{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schoolmistress_story_paragraphs = open('schoolmistress_paragraphs.txt', 'r').readlines()\n",
    "el_story_paragraphs = open('expensivelessons_paragraphs.txt', 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_highlights(filename, story_paragraphs):\n",
    "  highlight_file = open(f'./highlighting_logs/{filename}.log', 'r')\n",
    "  cleaned_file = open(f'./backend/highlights/{filename.split(\"_\")[0]}_{\"schoolmistress\" if \"schoolmistress\" in filename else \"expensivelessons\"}_cleaned.log', 'w')\n",
    "  lines = highlight_file.readlines()\n",
    "  highlights = [None] * len(story_paragraphs)\n",
    "  for line in lines:\n",
    "    start = line.find('Highlight:')\n",
    "    if start != -1:\n",
    "      highlight = json.loads(str(line[start + len('Highlight: '):].replace(\"'\", '\"')), )\n",
    "      par = highlight.pop(-1)['paragraph']\n",
    "      highlights[par] = json.dumps(highlight)\n",
    "  for i in range(len(highlights)):\n",
    "    if highlights[i] != None:\n",
    "      cleaned_file.write(str(highlights[i]) + '\\n')\n",
    "    else:\n",
    "      cleaned_file.write('[]\\n')\n",
    "  cleaned_file.close()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGHLIGHT_DIR = \"./highlighting_logs/\"\n",
    "survey_df = pd.DataFrame()\n",
    "for filename in os.listdir(HIGHLIGHT_DIR):\n",
    "    f = os.path.join(HIGHLIGHT_DIR,filename)\n",
    "    if os.path.isfile(f):\n",
    "        filename = f.replace(HIGHLIGHT_DIR, '').replace('.log', '')\n",
    "        if 'schoolmistress' in filename:\n",
    "          parse_highlights(filename, schoolmistress_story_paragraphs)\n",
    "        else:\n",
    "          parse_highlights(filename, el_story_paragraphs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_of_coordinates_in_rectangle(top_left, bottom_right, width, height):\n",
    "    x1, y1 = top_left\n",
    "    x2, y2 = bottom_right\n",
    "    x_vals = np.linspace(x1, x2, width, dtype=np.int64)\n",
    "    y_vals = np.linspace(y1, y2, height, dtype=np.int64)\n",
    "    x_grid, y_grid = np.meshgrid(x_vals, y_vals)\n",
    "    return x_grid, y_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_coord_in_rectangle(coord, top_left, bottom_right):\n",
    "    x, y = coord\n",
    "    x1, y1 = top_left\n",
    "    x2, y2 = bottom_right\n",
    "    return x1 <= x <= x2 and y1 <= y <= y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid, y_grid = create_grid_of_coordinates_in_rectangle([0, 0], (1440, 900), 200, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print x_grid to file as json\n",
    "with open('x_grid.txt', 'w') as f:\n",
    "    f.write(json.dumps(x_grid.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print y_grid to file as json\n",
    "with open('y_grid.txt', 'w') as f:\n",
    "    f.write(json.dumps(y_grid.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top left and bottom right from backend/logs/rose2.txt\n",
    "with(open('backend/logs/schoolmistress_sentence_coords.txt', 'r')) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "top_lefts_sm = []\n",
    "bottom_rights_sm = []\n",
    "sent_counts_sm = []\n",
    "for line in lines:\n",
    "    line_dict = json.loads(line.replace(\"'\", '\"'))\n",
    "    if 'count' in line_dict.keys():\n",
    "        sent_counts_sm.append(line_dict['count'])\n",
    "    else:\n",
    "        top_lefts_sm.append(line_dict['top_left'])\n",
    "        bottom_rights_sm.append(line_dict['bottom_right'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top left and bottom right from backend/logs/rose2.txt\n",
    "with(open('backend/logs/expensivelessons_sentence_coords.txt', 'r')) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "top_lefts_el = []\n",
    "bottom_rights_el = []\n",
    "sent_counts_el = []\n",
    "for line in lines:\n",
    "    line_dict = json.loads(line.replace(\"'\", '\"'))\n",
    "    if 'count' in line_dict.keys():\n",
    "        sent_counts_el.append(line_dict['count'])\n",
    "    else:\n",
    "        top_lefts_el.append(line_dict['top_left'])\n",
    "        bottom_rights_el.append(line_dict['bottom_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_df = pd.read_csv('backend/dwell_times/id2_schoolmistress.csv')\n",
    "len(participant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df2 = pd.read_csv('backend/dwell_times/id2_el.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coordinates(story, sent_counts, top_lefts, bottom_rights, x_grid, y_grid, story_len):\n",
    "    total_count=0\n",
    "    for page in range(len(sent_counts)):\n",
    "        coord_dicts = []\n",
    "        \n",
    "        for coords in zip(x_grid.flatten(), y_grid.flatten()):\n",
    "            coord_dict = {}\n",
    "            coord_dict['x'] = coords[0]\n",
    "            coord_dict['y'] = coords[1]\n",
    "            for i in range(total_count, total_count + sent_counts[page]):\n",
    "                if check_if_coord_in_rectangle(coords, top_lefts[i], bottom_rights[i]):\n",
    "                    coord_dict['sentence'] = i\n",
    "                    # coord_dict['dwell_time'] = int(participant_df.iloc[i]['IA_DWELL_TIME_SMOOTHED'] / participant_df.iloc[i]['word'])\n",
    "                    coord_dicts.append(coord_dict)\n",
    "        total_count=total_count+sent_counts[page]\n",
    "        gaze_durations = pd.DataFrame.from_dict(coord_dicts)\n",
    "        gaze_durations.to_csv(f'backend/coordinates/{story}{str(page)}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_coordinates('schoolmistress', sent_counts_sm, top_lefts_sm, bottom_rights_sm, x_grid, y_grid, len(participant_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_coordinates('expensivelessons', sent_counts_el, top_lefts_el, bottom_rights_el, x_grid, y_grid, len(participant_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files in backend/dwell_times\n",
    "# for each file, read in the dwell times\n",
    "# for each page, read in the coordinates\n",
    "# for each coordinate, add the dwell time to the coordinate\n",
    "# write the coordinates to a file\n",
    "dwell_time_dir = 'backend/dwell_times/'\n",
    "for filename in os.listdir(dwell_time_dir):\n",
    "    f = os.path.join(dwell_time_dir, filename)\n",
    "    if os.path.isfile(f):\n",
    "        filename = f.replace(dwell_time_dir, '').replace('.csv', '')\n",
    "        if 'schoolmistress' in filename:\n",
    "            story = 'schoolmistress'\n",
    "        else:\n",
    "            story = 'expensivelessons'\n",
    "        participant_df = pd.read_csv(f)\n",
    "        sent_counts = sent_counts_sm if story == 'schoolmistress' else sent_counts_el\n",
    "        total_count=0\n",
    "        for page in range(len(sent_counts)):\n",
    "            coord_df = pd.read_csv(f'backend/coordinates/{story}{str(page)}.csv', header=None, dtype=np.int64)\n",
    "            coord_df.columns = ['x', 'y', 'sentence']\n",
    "            for i in range(total_count, total_count + sent_counts[page]):\n",
    "                if i < len(participant_df):\n",
    "                    coord_df.loc[coord_df['sentence'] == i, 'dwell_time'] = int(participant_df.iloc[i]['IA_DWELL_TIME_SMOOTHED'] / participant_df.iloc[i]['word'])\n",
    "                else:\n",
    "                    coord_df.loc[coord_df['sentence'] == i, 'dwell_time'] = int(participant_df.iloc[-1]['IA_DWELL_TIME_SMOOTHED'] / participant_df.iloc[-1]['word'])\n",
    "            total_count=total_count+sent_counts[page]\n",
    "            coord_df.drop(columns=['sentence'], inplace=True)\n",
    "            coord_df['dwell_time'] = coord_df['dwell_time'].astype(np.int64)\n",
    "            coord_df.to_csv(f'backend/heatmap/{filename}-{str(page)}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346.0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_df.iloc[0]['IA_DWELL_TIME_SMOOTHED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence object\n",
    "class Sentence:\n",
    "    def __init__(self, sentence, paragraph, sentence_index, paragraph_index, story_index, story_name):\n",
    "        self.sentence = sentence\n",
    "        self.paragraph = paragraph\n",
    "        self.sentence_index = sentence_index\n",
    "        self.paragraph_index = paragraph_index\n",
    "        self.story_index = story_index\n",
    "        self.story_name = story_name\n",
    "        self.highlighted = False\n",
    "        self.highlighted_by = []\n",
    "        self.highlighted_by_index = []\n",
    "        self.highlighted_by_story_index = []\n",
    "        self.highlighted_by_story_name = []\n",
    "        self.highlighted_by_sentence_index = []\n",
    "        self.highlighted_by_paragraph_index = []\n",
    "        self.highlighted_by_sentence = []\n",
    "        self.highlighted_by_paragraph = []\n",
    "        self.highlighted_by_sentence_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lines in backend/stories/schoolmistress.txt\n",
    "with(open('backend/stories/expensivelessons.txt', 'r')) as f:\n",
    "    story_lines = f.readlines()\n",
    "\n",
    "# split lines by punctuation\n",
    "all_sentences = []\n",
    "for line in story_lines:\n",
    "    line = line.replace('?', '.').replace('!', '.').replace(\"....\\\"\", \",\\\"\").replace(\"....\", \".\").replace('”', '\"').replace('“', '\"').replace('’', \"'\").replace('‘', \"'\")\n",
    "    sentences = line.split('.')\n",
    "    # remove empty strings and quotes\n",
    "    sentences = [sentence for sentence in sentences if sentence != '' and sentence != '\"' and sentence != '\"\\n' and sentence != '\\n']\n",
    "    sentences = list(map(lambda sentence: \"<span>\"+sentence+\"</span>\", sentences))\n",
    "    all_sentences.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('backend/stories/expensivelessons_modified.txt', 'w') as f:\n",
    "    for sentences in all_sentences:\n",
    "        for sentence in sentences:\n",
    "            f.write(sentence+'.')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "obj = '{\"top_left\": [1, 2], \"bottom_right\": [2, 4]}'\n",
    "print(json.loads(obj).get('top_left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rose2.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "narrative_engagement-1kgk4Qlh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce6e9f89b8ba06df44163b972ee2537d17b2ddac401432716e00090db9961c19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
